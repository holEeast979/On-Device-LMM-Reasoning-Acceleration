#!/usr/bin/env python3
"""
å®éªŒï¼šä¸²è¡Œ vs å¹¶è¡Œæ¨ç†å¯¹æ¯”
ç›®æ ‡ï¼šæ‰¾å‡ºå¹¶è¡Œè¾“å…¥æ—¶å“ªä¸ªé˜¶æ®µå½±å“æ¨ç†æ—¶é—´

ç»Ÿä¸€ä½¿ç”¨ç›¸åŒpromptï¼Œé¿å…ç”Ÿæˆé•¿åº¦å·®å¼‚
é‡ç‚¹å¯¹æ¯”ï¼šencodeã€prefillã€decode å„é˜¶æ®µæ—¶é—´
"""

from __future__ import annotations
import argparse, os, sys, gc, time, threading
import cv2, numpy as np, pandas as pd, torch
from tqdm import tqdm

# å¯¼å…¥è·¯å¾„è®¾ç½®
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
if PROJECT_DIR not in sys.path:
    sys.path.insert(0, PROJECT_DIR)

import common as C
from transformers.generation.streamers import BaseStreamer

class TokenTimingStreamer(BaseStreamer):
    def __init__(self):
        super().__init__()
        self.first_token_time = None
    
    def put(self, value):
        if self.first_token_time is None:
            self.first_token_time = time.perf_counter()
    
    def end(self):
        pass

def clear_gpu():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

def load_samples(images_csv, videos_csv, n, n_frames):
    samples = {"image": [], "video": []}
    
    # åŠ è½½å›¾ç‰‡
    for _, row in pd.read_csv(images_csv).head(n).iterrows():
        if os.path.exists(row["image_path"]):
            img = cv2.imread(row["image_path"])
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                h, w = img.shape[:2]
                if max(h,w) > 512:
                    scale = 512/max(h,w)
                    img = cv2.resize(img, (int(w*scale), int(h*scale)))
                samples["image"].append(img)
    
    # åŠ è½½è§†é¢‘
    for _, row in pd.read_csv(videos_csv).head(n).iterrows():
        if os.path.exists(row["video_path"]):
            frames, _, _ = C.sample_video_frames(row["video_path"], n_frames, 336)
            if frames:
                samples["video"].append(frames)
    
    return samples

def measure_inference(model, proc, images, test_name, sample_id, max_tokens):
    """ç»Ÿä¸€æµ‹é‡å‡½æ•° - é’ˆå¯¹ç¼–ç ç“¶é¢ˆåˆ†æ"""
    clear_gpu()
    
    # ç»Ÿä¸€prompt - æ‰€æœ‰æµ‹è¯•ä½¿ç”¨å®Œå…¨ç›¸åŒçš„é—®é¢˜
    question = "Describe what you see in one sentence."
    
    # 1. Encodeé˜¶æ®µ - é‡ç‚¹ç›‘æ§
    n_imgs = len(images)
    content = [{"type": "image"}] * n_imgs + [{"type": "text", "text": question}]
    text = proc.apply_chat_template([{"role": "user", "content": content}], 
                                   tokenize=False, add_generation_prompt=True)
    
    torch.cuda.synchronize()
    t_encode_start = time.perf_counter()
    inputs = proc(text=text, images=images, return_tensors="pt").to(model.device)
    torch.cuda.synchronize()
    encode_ms = (time.perf_counter() - t_encode_start) * 1000
    
    input_tokens = inputs.input_ids.shape[1]
    
    # 2. Prefill + Decode é˜¶æ®µ - åˆ†ç¦»æµ‹é‡
    streamer = TokenTimingStreamer()
    outputs_container = {}
    
    def _generate():
        with torch.no_grad():
            out = model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                do_sample=False,  # å›ºå®šè§£ç ç­–ç•¥
                streamer=streamer,
                return_audio=False,
                pad_token_id=proc.tokenizer.eos_token_id,
            )
        outputs_container["outputs"] = out
    
    torch.cuda.synchronize()
    t_gen_start = time.perf_counter()
    
    worker = threading.Thread(target=_generate)
    worker.start()
    worker.join()
    
    torch.cuda.synchronize()
    t_gen_end = time.perf_counter()
    
    # è®¡ç®—æ—¶é—´
    total_gen_ms = (t_gen_end - t_gen_start) * 1000
    if streamer.first_token_time is None:
        prefill_ms = total_gen_ms
        decode_ms = 0
    else:
        prefill_ms = (streamer.first_token_time - t_gen_start) * 1000
        decode_ms = (t_gen_end - streamer.first_token_time) * 1000
        decode_ms = max(0, decode_ms)
    
    out = outputs_container.get("outputs")
    n_tokens = out.shape[1] - input_tokens if out is not None else 0
    
    # è®¡ç®—æ¯token decodeæ—¶é—´ï¼ˆæ’é™¤ç¬¬ä¸€ä¸ªtokenï¼‰
    per_token_decode_ms = decode_ms / max(1, n_tokens - 1) if n_tokens > 1 else 0
    
    total_ms = encode_ms + total_gen_ms
    
    # æ¸…ç†
    del inputs
    if out is not None:
        del out
    clear_gpu()
    
    return {
        "test": test_name,
        "sample_id": sample_id,
        "input_tokens": input_tokens,
        "n_tokens": n_tokens,
        "encode_ms": encode_ms,
        "prefill_ms": prefill_ms,
        "decode_ms": decode_ms,
        "per_token_decode_ms": per_token_decode_ms,
        "total_ms": total_ms,
        "n_images": n_imgs,
    }

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--qwen25-omni", required=True)
    parser.add_argument("--images", required=True)
    parser.add_argument("--videos", required=True)
    parser.add_argument("--out", default="/root/autodl-tmp/results/exp4_serial_vs_parallel.csv")
    parser.add_argument("--frames", type=int, default=4)
    parser.add_argument("--n-samples", type=int, default=30)
    parser.add_argument("--max-tokens", type=int, default=32)  # æ§åˆ¶ç”Ÿæˆé•¿åº¦
    args = parser.parse_args()
    
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    
    print("Loading model...")
    model, proc = C.load_qwen25_omni(args.qwen25_omni, "bf16")
    
    print("Loading samples...")
    samples = load_samples(args.images, args.videos, args.n_samples, args.frames)
    n = min(len(samples["image"]), len(samples["video"]))
    print(f"Using {n} samples")
    
    results = []
    
    # ä¸²è¡Œæµ‹è¯• - ä½¿ç”¨ç›¸åŒæ ·æœ¬å¯¹
    print("\n--- Serial: Image Only ---")
    for i in tqdm(range(n), desc="Serial Image"):
        try:
            r = measure_inference(model, proc, [samples["image"][i]], 
                                "serial_image", i, args.max_tokens)
            results.append(r)
        except Exception as e:
            print(f"Serial image {i} error: {e}")
    
    print("--- Serial: Video Only ---")
    for i in tqdm(range(n), desc="Serial Video"):
        try:
            r = measure_inference(model, proc, samples["video"][i], 
                                "serial_video", i, args.max_tokens)
            results.append(r)
        except Exception as e:
            print(f"Serial video {i} error: {e}")
    
    # å¹¶è¡Œæµ‹è¯• - ä½¿ç”¨ç›¸åŒçš„æ ·æœ¬å¯¹è¿›è¡Œç»„åˆ
    print("--- Parallel: Image + Video ---")
    for i in tqdm(range(n), desc="Parallel Both"):
        try:
            all_imgs = [samples["image"][i]] + samples["video"][i]
            r = measure_inference(model, proc, all_imgs, 
                                "parallel_both", i, args.max_tokens)
            results.append(r)
        except Exception as e:
            print(f"Parallel {i} error: {e}")
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    cols = ["test", "sample_id", "input_tokens", "n_tokens", "n_images", 
            "encode_ms", "prefill_ms", "decode_ms", "per_token_decode_ms", "total_ms"]
    df = df[cols]
    df.to_csv(args.out, index=False)
    print(f"\nSaved: {args.out}")
    
    # ================== ç¼–ç ç“¶é¢ˆåˆ†æ ==================
    print("\n" + "="*80)
    print("ğŸ” å¤šæ¨¡æ€å¹¶è¡Œç¼–ç ç“¶é¢ˆåˆ†æ")
    print("="*80)
    
    img_data = df[df["test"] == "serial_image"]
    vid_data = df[df["test"] == "serial_video"] 
    par_data = df[df["test"] == "parallel_both"]
    
    if any(x.empty for x in [img_data, vid_data, par_data]):
        print("âŒ æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•åˆ†æ")
        return
    
    # 1. å„é˜¶æ®µåŸºç¡€ç»Ÿè®¡
    print("\nğŸ“Š å„é˜¶æ®µåŸºç¡€ç»Ÿè®¡:")
    for test_name, data, icon in [("Imageå•ç‹¬", img_data, "ğŸ–¼ï¸"), 
                                  ("Videoå•ç‹¬", vid_data, "ğŸ¥"),
                                  ("å¹¶è¡Œè¾“å…¥", par_data, "ğŸ”„")]:
        print(f"\n{icon} {test_name}:")
        print(f"   è¾“å…¥tokens:     {data['input_tokens'].mean():.0f}")
        print(f"   è¾“å‡ºtokens:     {data['n_tokens'].mean():.1f}")
        print(f"   Encode:         {data['encode_ms'].mean():.1f}ms")
        print(f"   Prefill:        {data['prefill_ms'].mean():.1f}ms")
        print(f"   æ¯tokenè§£ç :    {data['per_token_decode_ms'].mean():.1f}ms")
    
    # 2. å…³é”®å¯¹æ¯”ï¼šä¸²è¡Œå’Œ vs å¹¶è¡Œ
    print(f"\nğŸ”¥ å…³é”®å¯¹æ¯”ï¼šä¸²è¡Œé€»è¾‘å’Œ vs å¹¶è¡Œå®é™…")
    print("-" * 60)
    
    encode_serial = img_data['encode_ms'].mean() + vid_data['encode_ms'].mean()
    encode_parallel = par_data['encode_ms'].mean()
    encode_diff = encode_parallel - encode_serial
    
    prefill_serial = img_data['prefill_ms'].mean() + vid_data['prefill_ms'].mean()
    prefill_parallel = par_data['prefill_ms'].mean()
    prefill_diff = prefill_parallel - prefill_serial
    
    total_serial = img_data['total_ms'].mean() + vid_data['total_ms'].mean()
    total_parallel = par_data['total_ms'].mean()
    
    print(f"Encodeé˜¶æ®µ:")
    print(f"   ä¸²è¡Œå’Œ:  {encode_serial:.1f}ms")
    print(f"   å¹¶è¡Œ:    {encode_parallel:.1f}ms")
    print(f"   å·®å¼‚:    {encode_diff:+.1f}ms ({encode_diff/encode_serial*100:+.1f}%)")
    
    print(f"\nPrefillé˜¶æ®µ:")
    print(f"   ä¸²è¡Œå’Œ:  {prefill_serial:.1f}ms")
    print(f"   å¹¶è¡Œ:    {prefill_parallel:.1f}ms") 
    print(f"   å·®å¼‚:    {prefill_diff:+.1f}ms ({prefill_diff/prefill_serial*100:+.1f}%)")
    
    # 3. ç“¶é¢ˆè¯†åˆ«
    print(f"\nğŸ¯ ç“¶é¢ˆè¯†åˆ«:")
    print("-" * 40)
    
    # è®¡ç®—å„é˜¶æ®µå æ¯”
    par_encode_pct = par_data['encode_ms'].mean() / par_data['total_ms'].mean() * 100
    par_prefill_pct = par_data['prefill_ms'].mean() / par_data['total_ms'].mean() * 100
    par_decode_pct = par_data['decode_ms'].mean() / par_data['total_ms'].mean() * 100
    
    print(f"å¹¶è¡Œæ¨ç†å„é˜¶æ®µå æ¯”:")
    print(f"   Encode:   {par_encode_pct:.1f}%")
    print(f"   Prefill:  {par_prefill_pct:.1f}%") 
    print(f"   Decode:   {par_decode_pct:.1f}%")
    
    # æ‰¾å‡ºæœ€å¤§ç“¶é¢ˆ
    bottlenecks = [
        ("Encode", abs(encode_diff), par_encode_pct),
        ("Prefill", abs(prefill_diff), par_prefill_pct),
    ]
    bottlenecks.sort(key=lambda x: x[1], reverse=True)
    
    print(f"\nğŸ”´ æœ€å½±å“å¹¶è¡Œç¼–ç æ—¶é—´çš„å› ç´ :")
    print(f"   1. {bottlenecks[0][0]}: å·®å¼‚{bottlenecks[0][1]:.1f}ms, å æ€»æ—¶é—´{bottlenecks[0][2]:.1f}%")
    print(f"   2. {bottlenecks[1][0]}: å·®å¼‚{bottlenecks[1][1]:.1f}ms, å æ€»æ—¶é—´{bottlenecks[1][2]:.1f}%")
    
    # 4. æ€»ç»“
    print(f"\nâœ… æ€»ç»“:")
    efficiency = (1 - total_parallel/total_serial) * 100
    if efficiency > 0:
        print(f"   å¹¶è¡Œæ¯”ä¸²è¡Œå¿« {efficiency:.1f}%")
    else:
        print(f"   å¹¶è¡Œæ¯”ä¸²è¡Œæ…¢ {-efficiency:.1f}%")
    print(f"   ä¸»è¦åŸå› : {bottlenecks[0][0]}é˜¶æ®µçš„{'å¢åŠ ' if encode_diff > 0 else 'å‡å°‘'}")
    
    print("="*80)

if __name__ == "__main__":
    main()
