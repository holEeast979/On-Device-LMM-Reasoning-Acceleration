#!/usr/bin/env python3
"""
å®éªŒ5ï¼šæ¨¡å—çº§åˆ«è€—æ—¶åˆ†æ
ç”¨Hookç²¾ç¡®æµ‹é‡Qwen2.5-Omniå„æ¨¡å—çš„è€—æ—¶
é‡ç‚¹ï¼šå¤šæ¨¡æ€ç‰¹æœ‰æ¨¡å—ï¼ˆVision Encoder, Audio Encoder, æŠ•å½±å±‚ï¼‰
"""

from __future__ import annotations
import argparse, os, sys, gc, time
import cv2, numpy as np, pandas as pd, torch
from collections import OrderedDict

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
if PROJECT_DIR not in sys.path:
    sys.path.insert(0, PROJECT_DIR)

import common as C


def print_model_structure(model, max_depth=3):
    """æ‰“å°æ¨¡å‹ç»“æ„ï¼Œæ‰¾å‡ºå…³é”®æ¨¡å—"""
    print("\n" + "="*80)
    print("ğŸ“¦ æ¨¡å‹ç»“æ„æ¢æµ‹")
    print("="*80)
    
    modules_info = []
    for name, module in model.named_modules():
        depth = name.count('.')
        if depth <= max_depth and name:  # åªæ‰“å°å‰å‡ å±‚
            class_name = module.__class__.__name__
            # ç»Ÿè®¡å‚æ•°é‡
            params = sum(p.numel() for p in module.parameters(recurse=False))
            if params > 0 or depth <= 1:
                indent = "  " * depth
                modules_info.append((name, class_name, params, depth))
                if params > 1e6:
                    print(f"{indent}ğŸ“Œ {name}: {class_name} ({params/1e6:.1f}M params)")
                elif depth <= 1:
                    print(f"{indent}ğŸ“ {name}: {class_name}")
    
    return modules_info


def find_key_modules(model):
    """è‡ªåŠ¨æ‰¾å‡ºå…³é”®çš„å¤šæ¨¡æ€æ¨¡å—"""
    key_modules = {}
    
    # éå†æŸ¥æ‰¾å…³é”®æ¨¡å—
    for name, module in model.named_modules():
        name_lower = name.lower()
        
        # Visionç›¸å…³
        if any(k in name_lower for k in ['visual', 'vision', 'vit', 'image_encoder']):
            if 'merger' in name_lower or 'proj' in name_lower:
                key_modules['vision_projector'] = name
            elif name.count('.') <= 2:  # é¡¶å±‚visionæ¨¡å—
                key_modules['vision_encoder'] = name
        
        # Audioç›¸å…³
        if any(k in name_lower for k in ['audio', 'whisper', 'speech']):
            if 'proj' in name_lower:
                key_modules['audio_projector'] = name
            elif name.count('.') <= 2:
                key_modules['audio_encoder'] = name
        
        # LLMç›¸å…³
        if any(k in name_lower for k in ['language', 'llm', 'lm_head', 'embed_tokens']):
            if name.count('.') <= 2:
                key_modules['llm'] = name
        
        # Thinker/Talker
        if name == 'thinker':
            key_modules['thinker'] = name
        if name == 'talker':
            key_modules['talker'] = name
    
    return key_modules


class ModuleTimer:
    """æ¨¡å—è®¡æ—¶å™¨ï¼Œç”¨Hookè®°å½•å„æ¨¡å—è€—æ—¶"""
    
    def __init__(self):
        self.timings = OrderedDict()
        self.start_times = {}
        self.hooks = []
    
    def _make_pre_hook(self, name):
        def hook(module, input):
            torch.cuda.synchronize()
            self.start_times[name] = time.perf_counter()
        return hook
    
    def _make_post_hook(self, name):
        def hook(module, input, output):
            torch.cuda.synchronize()
            end_time = time.perf_counter()
            if name in self.start_times:
                elapsed = (end_time - self.start_times[name]) * 1000
                if name not in self.timings:
                    self.timings[name] = []
                self.timings[name].append(elapsed)
        return hook
    
    def register(self, model, module_names):
        """æ³¨å†Œè¦ç›‘æ§çš„æ¨¡å—"""
        for name, module in model.named_modules():
            if name in module_names:
                pre_hook = module.register_forward_pre_hook(self._make_pre_hook(name))
                post_hook = module.register_forward_hook(self._make_post_hook(name))
                self.hooks.append(pre_hook)
                self.hooks.append(post_hook)
                print(f"  âœ… å·²æ³¨å†ŒHook: {name}")
    
    def clear(self):
        """æ¸…é™¤è®¡æ—¶æ•°æ®"""
        self.timings.clear()
        self.start_times.clear()
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰Hook"""
        for hook in self.hooks:
            hook.remove()
        self.hooks.clear()
    
    def get_summary(self):
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        summary = {}
        for name, times in self.timings.items():
            summary[name] = {
                'mean': np.mean(times),
                'std': np.std(times),
                'min': np.min(times),
                'max': np.max(times),
                'count': len(times),
            }
        return summary


def run_inference(model, proc, images, question="Describe what you see."):
    """è¿è¡Œä¸€æ¬¡æ¨ç†"""
    gc.collect()
    torch.cuda.empty_cache()
    
    n_imgs = len(images)
    content = [{"type": "image"}] * n_imgs + [{"type": "text", "text": question}]
    text = proc.apply_chat_template(
        [{"role": "user", "content": content}], 
        tokenize=False, 
        add_generation_prompt=True
    )
    
    inputs = proc(text=text, images=images, return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=16,
            do_sample=False,
            return_audio=False,
        )
    
    return outputs


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--qwen25-omni", required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--images", required=True, help="å›¾åƒmanifest")
    parser.add_argument("--videos", required=True, help="è§†é¢‘manifest")
    parser.add_argument("--out", default="/root/autodl-tmp/results/exp5_module_timing.csv")
    parser.add_argument("--n-samples", type=int, default=10, help="æ ·æœ¬æ•°")
    parser.add_argument("--frames", type=int, default=4, help="è§†é¢‘å¸§æ•°")
    parser.add_argument("--print-structure", action="store_true", help="åªæ‰“å°æ¨¡å‹ç»“æ„")
    args = parser.parse_args()
    
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”„ åŠ è½½æ¨¡å‹...")
    model, proc = C.load_qwen25_omni(args.qwen25_omni, "bf16")
    
    # æ‰“å°æ¨¡å‹ç»“æ„
    modules_info = print_model_structure(model, max_depth=2)
    
    # æ‰¾å‡ºå…³é”®æ¨¡å—
    print("\n" + "="*80)
    print("ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°çš„å…³é”®æ¨¡å—")
    print("="*80)
    key_modules = find_key_modules(model)
    for role, name in key_modules.items():
        print(f"  {role}: {name}")
    
    if args.print_structure:
        # æ‰“å°æ›´è¯¦ç»†çš„ç»“æ„
        print("\n" + "="*80)
        print("ğŸ“‹ å®Œæ•´æ¨¡å—åˆ—è¡¨ï¼ˆå‰4å±‚ï¼‰")
        print("="*80)
        for name, module in model.named_modules():
            if name.count('.') <= 3:
                print(f"  {name}: {module.__class__.__name__}")
        return
    
    # æ ¹æ®æ¢æµ‹ç»“æœç¡®å®šçš„å®é™…æ¨¡å—è·¯å¾„
    # æ›´ç»†ç²’åº¦ï¼šç›‘æ§æ¯ä¸€å±‚
    modules_to_monitor = [
        # ========== Vision Encoder ç»†ç²’åº¦ ==========
        "thinker.visual",                    # æ•´ä½“
        "thinker.visual.patch_embed",        # Patch Embedding
        "thinker.visual.patch_embed.proj",   # Conv3d
        "thinker.visual.merger",             # èåˆå±‚
        "thinker.visual.merger.mlp",         # èåˆMLP
    ]
    
    # æ·»åŠ ViTæ¯ä¸€å±‚ï¼ˆ32å±‚ï¼‰
    for i in range(32):
        modules_to_monitor.append(f"thinker.visual.blocks.{i}")
    
    # å¦‚æœéœ€è¦å¯¹æ¯”LLMï¼ˆåªå–å‡ å±‚ä½œä¸ºå‚è€ƒï¼‰
    modules_to_monitor.extend([
        "thinker.model",                     # æ•´ä½“LLM
        "thinker.model.embed_tokens",        # Embedding
        "thinker.lm_head",                   # è¾“å‡ºå¤´
        # LLMå±‚é‡‡æ ·ï¼ˆä¸å…¨éƒ¨ç›‘æ§ï¼Œå¤ªå¤šäº†ï¼‰
        "thinker.model.layers.0",            # ç¬¬1å±‚
        "thinker.model.layers.13",           # ä¸­é—´å±‚
        "thinker.model.layers.27",           # æœ€åä¸€å±‚
    ])
    
    # è¿‡æ»¤å‡ºå®é™…å­˜åœ¨çš„æ¨¡å—
    existing_modules = set(name for name, _ in model.named_modules())
    modules_to_monitor = [m for m in modules_to_monitor if m in existing_modules]
    
    print("\n" + "="*80)
    print("â±ï¸ æ³¨å†Œè®¡æ—¶Hook")
    print("="*80)
    timer = ModuleTimer()
    timer.register(model, modules_to_monitor)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ”„ åŠ è½½æµ‹è¯•æ•°æ®...")
    
    # åŠ è½½å›¾ç‰‡
    images_list = []
    img_df = pd.read_csv(args.images).head(args.n_samples)
    for _, row in img_df.iterrows():
        if os.path.exists(row["image_path"]):
            img = cv2.imread(row["image_path"])
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                h, w = img.shape[:2]
                if max(h, w) > 512:
                    scale = 512 / max(h, w)
                    img = cv2.resize(img, (int(w*scale), int(h*scale)))
                images_list.append(img)
    
    # åŠ è½½è§†é¢‘
    videos_list = []
    vid_df = pd.read_csv(args.videos).head(args.n_samples)
    for _, row in vid_df.iterrows():
        if os.path.exists(row["video_path"]):
            frames, _, _ = C.sample_video_frames(row["video_path"], args.frames, 336)
            if frames:
                videos_list.append(frames)
    
    n = min(len(images_list), len(videos_list), args.n_samples)
    print(f"  ä½¿ç”¨ {n} ä¸ªæ ·æœ¬")
    
    results = []
    
    # æµ‹è¯•1: Imageå•ç‹¬
    print("\n" + "="*80)
    print("ğŸ–¼ï¸ æµ‹è¯•: Imageå•ç‹¬")
    print("="*80)
    timer.clear()
    for i in range(n):
        print(f"  æ ·æœ¬ {i+1}/{n}", end="\r")
        run_inference(model, proc, [images_list[i]])
    
    img_summary = timer.get_summary()
    for name, stats in img_summary.items():
        results.append({
            "test": "image",
            "module": name,
            "mean_ms": stats['mean'],
            "std_ms": stats['std'],
            "count": stats['count'],
        })
        print(f"  {name}: {stats['mean']:.2f} Â± {stats['std']:.2f} ms")
    
    # æµ‹è¯•2: Videoå•ç‹¬
    print("\n" + "="*80)
    print("ğŸ¥ æµ‹è¯•: Videoå•ç‹¬")
    print("="*80)
    timer.clear()
    for i in range(n):
        print(f"  æ ·æœ¬ {i+1}/{n}", end="\r")
        run_inference(model, proc, videos_list[i])
    
    vid_summary = timer.get_summary()
    for name, stats in vid_summary.items():
        results.append({
            "test": "video",
            "module": name,
            "mean_ms": stats['mean'],
            "std_ms": stats['std'],
            "count": stats['count'],
        })
        print(f"  {name}: {stats['mean']:.2f} Â± {stats['std']:.2f} ms")
    
    # æµ‹è¯•3: Image+Videoå¹¶è¡Œ
    print("\n" + "="*80)
    print("ğŸ”„ æµ‹è¯•: Image+Videoå¹¶è¡Œ")
    print("="*80)
    timer.clear()
    for i in range(n):
        print(f"  æ ·æœ¬ {i+1}/{n}", end="\r")
        all_imgs = [images_list[i]] + videos_list[i]
        run_inference(model, proc, all_imgs)
    
    par_summary = timer.get_summary()
    for name, stats in par_summary.items():
        results.append({
            "test": "parallel",
            "module": name,
            "mean_ms": stats['mean'],
            "std_ms": stats['std'],
            "count": stats['count'],
        })
        print(f"  {name}: {stats['mean']:.2f} Â± {stats['std']:.2f} ms")
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(args.out, index=False)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {args.out}")
    
    # åˆ†æå¯¹æ¯”
    print("\n" + "="*80)
    print("ğŸ“Š æ¨¡å—çº§åˆ«ç“¶é¢ˆåˆ†æ")
    print("="*80)
    
    # 1. é¡¶å±‚æ¨¡å—å¯¹æ¯”
    top_modules = ["thinker.visual", "thinker.visual.patch_embed", 
                   "thinker.visual.merger", "thinker.model"]
    
    for module in top_modules:
        img_time = img_summary.get(module, {}).get('mean', 0)
        vid_time = vid_summary.get(module, {}).get('mean', 0)
        par_time = par_summary.get(module, {}).get('mean', 0)
        serial_sum = img_time + vid_time
        
        if serial_sum > 0:
            diff = par_time - serial_sum
            diff_pct = (diff / serial_sum) * 100
            
            print(f"\nğŸ“Œ {module}:")
            print(f"   Image:      {img_time:.2f} ms")
            print(f"   Video:      {vid_time:.2f} ms")
            print(f"   ä¸²è¡Œå’Œ:     {serial_sum:.2f} ms")
            print(f"   å¹¶è¡Œ:       {par_time:.2f} ms")
            print(f"   å·®å¼‚:       {diff:+.2f} ms ({diff_pct:+.1f}%)")
    
    # 2. ViTæ¯å±‚è¯¦ç»†åˆ†æ
    print("\n" + "="*80)
    print("ğŸ”¬ ViT æ¯å±‚è€—æ—¶åˆ†å¸ƒï¼ˆå¤šæ¨¡æ€æ ¸å¿ƒï¼‰")
    print("="*80)
    print(f"{'Layer':<30} {'Image':>10} {'Video':>10} {'Parallel':>10} {'Serial':>10} {'Diff%':>10}")
    print("-"*80)
    
    vit_layers_img = []
    vit_layers_vid = []
    vit_layers_par = []
    
    for i in range(32):
        layer_name = f"thinker.visual.blocks.{i}"
        img_time = img_summary.get(layer_name, {}).get('mean', 0)
        vid_time = vid_summary.get(layer_name, {}).get('mean', 0)
        par_time = par_summary.get(layer_name, {}).get('mean', 0)
        serial_sum = img_time + vid_time
        
        vit_layers_img.append(img_time)
        vit_layers_vid.append(vid_time)
        vit_layers_par.append(par_time)
        
        if serial_sum > 0:
            diff_pct = (par_time / serial_sum - 1) * 100
            print(f"{layer_name:<30} {img_time:>10.2f} {vid_time:>10.2f} {par_time:>10.2f} {serial_sum:>10.2f} {diff_pct:>+10.1f}%")
    
    # 3. ViTå±‚ç»Ÿè®¡
    print("\n" + "-"*80)
    print("ğŸ“ˆ ViT Blocks ç»Ÿè®¡:")
    if vit_layers_img:
        total_img = sum(vit_layers_img)
        total_vid = sum(vit_layers_vid)
        total_par = sum(vit_layers_par)
        print(f"   Imageæ€»è®¡:    {total_img:.2f} ms")
        print(f"   Videoæ€»è®¡:    {total_vid:.2f} ms")
        print(f"   Parallelæ€»è®¡: {total_par:.2f} ms")
        print(f"   ä¸²è¡Œå’Œæ€»è®¡:   {total_img + total_vid:.2f} ms")
        if total_img + total_vid > 0:
            print(f"   å¹¶è¡Œæ•ˆç‡:     {(1 - total_par/(total_img + total_vid))*100:.1f}% èŠ‚çœ")
    
    # 4. æ—¶é—´å æ¯”åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š Vision Encoder å†…éƒ¨æ—¶é—´å æ¯”")
    print("="*80)
    
    for test_name, summary in [("Image", img_summary), ("Video", vid_summary), ("Parallel", par_summary)]:
        visual_total = summary.get("thinker.visual", {}).get('mean', 0)
        patch_embed = summary.get("thinker.visual.patch_embed", {}).get('mean', 0)
        merger = summary.get("thinker.visual.merger", {}).get('mean', 0)
        
        # ViT blocksæ€»æ—¶é—´
        vit_total = sum(summary.get(f"thinker.visual.blocks.{i}", {}).get('mean', 0) for i in range(32))
        
        if visual_total > 0:
            print(f"\n{test_name}:")
            print(f"   Patch Embed:  {patch_embed:>8.2f} ms ({patch_embed/visual_total*100:>5.1f}%)")
            print(f"   ViT Blocks:   {vit_total:>8.2f} ms ({vit_total/visual_total*100:>5.1f}%)")
            print(f"   Merger:       {merger:>8.2f} ms ({merger/visual_total*100:>5.1f}%)")
            print(f"   Total:        {visual_total:>8.2f} ms")
    
    # æ¸…ç†
    timer.remove_hooks()
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
